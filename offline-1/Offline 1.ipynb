{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.1\n",
    "dataframe = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.2\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.3\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.4\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.5\n",
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.duplicated(keep=False) # show all duplicated row indexes\n",
    "\n",
    "dataframe[dataframe.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #b.1\n",
    "# # handle the null values with the mean of the column\n",
    "# # Exclude the column 'column_to_exclude'\n",
    "# excluded_column = dataframe['Attrition']\n",
    "\n",
    "# # Drop the column and fill NaN values with the mean for the remaining columns\n",
    "# dataframe.drop(columns=['Attrition'], inplace=True)\n",
    "# dataframe.fillna(dataframe.mean(), inplace=True)\n",
    "\n",
    "# # Add the excluded column back to the dataframe\n",
    "# dataframe['Attrition'] = excluded_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.2\n",
    "dataframe.drop_duplicates(inplace=True)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.3\n",
    "dataframe.dropna(subset=['Attrition'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of input and output features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.1\n",
    "\n",
    "Features = dataframe.drop('Attrition', axis=1)# 1 for column, 0 for row\n",
    "Labels = dataframe['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion of features into numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "distinct_values_count = dataframe['Attrition'].nunique()\n",
    "\n",
    "if distinct_values_count == 2:\n",
    "    encoder = LabelEncoder()\n",
    "    Labels = encoder.fit_transform(Labels)\n",
    "    Labels = pd.DataFrame(Labels, columns=['Attrition'])\n",
    "else:\n",
    "    Labels = pd.get_dummies(Features, columns=['Attrition'])\n",
    "\n",
    "\n",
    "Labels#it is in array format\n",
    "#better approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.2\n",
    "#catagorical_cols = [col for col in Features.columns if Features[col].dtype == 'object']\n",
    "# Features= pd.get_dummies(Features, columns=catagorical_cols)\n",
    "\n",
    "catagorical_cols = []\n",
    "boolean_cols = []\n",
    "\n",
    "for col in Features.columns:\n",
    "    if Features[col].nunique()==2:\n",
    "        boolean_cols.append(col)\n",
    "        encoder = LabelEncoder()\n",
    "        Features[col] = encoder.fit_transform(Features[col])# not sure about this line \n",
    "    else:\n",
    "        if Features[col].dtype == 'object':\n",
    "            # Features[col] = pd.get_dummies(Features[col], columns=[col])\n",
    "            catagorical_cols.append(col)\n",
    "            Features[col] = Features[col].astype('category')\n",
    "\n",
    "print(catagorical_cols)\n",
    "print(boolean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#one hot encoding\n",
    "Features = pd.get_dummies(Features, columns=catagorical_cols)\n",
    "Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "# there is a problem with the data info that while prediction it may give more \n",
    "# importance to the larger value of the target column\n",
    "# we generally scale the features we dont scale the target column\n",
    "#min-max scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaling_cols = Features.columns.difference(catagorical_cols)\n",
    "scaling_cols = scaling_cols.difference(boolean_cols)\n",
    "\n",
    "def scale_min_max_features(Features):\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in scaling_cols:\n",
    "        Features[col] = scaler.fit_transform(Features[[col]])\n",
    "\n",
    "def scale_standard_features(Features):\n",
    "    scaler = StandardScaler()\n",
    "    for col in scaling_cols:\n",
    "        Features[col] = scaler.fit_transform(Features[[col]])\n",
    "\n",
    "# i have to exclude one hot encoded columns from the scaling\n",
    "\n",
    "scale_min_max_features(Features)\n",
    "# scale_standard_features(Features)z\n",
    "\n",
    "Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corelaiton scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f.1\n",
    "# correlation analysis of features with target\n",
    "label_series = Labels['Attrition']\n",
    "correlations = Features.corrwith(label_series).abs()\n",
    "correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_with_label = Features.copy()\n",
    "Features_with_label['Attrition'] = label_series\n",
    "\n",
    "correlation_matrix = Features_with_label.corr().abs()\n",
    "\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_correlations = correlations.sort_values(ascending=False).head(20)\n",
    "\n",
    "for col in top_20_correlations.index:\n",
    "    print(f'{col} : {top_20_correlations[col]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_columns = top_20_correlations.index.tolist()\n",
    "\n",
    "# Display the column names\n",
    "top_20_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "# Separate the data based on numeric labels\n",
    "class_0 = Features.loc[Labels[\"Attrition\"] == 0]\n",
    "class_1 = Features.loc[Labels[\"Attrition\"] == 1]\n",
    "\n",
    "\n",
    "def draw_plot(col_name, x_min=None, x_max=None):\n",
    "    # Create a 1D scatter plot for sepal_width with numeric labels\n",
    "    plt.plot(class_0[col_name], np.zeros_like(class_0[col_name]), 'o', label='Class No')\n",
    "    plt.plot(class_1[col_name], np.zeros_like(class_1[col_name]), 'o', label='Class Yes')\n",
    "\n",
    "    if x_min is not None and x_max is not None:\n",
    "        plt.xlim(x_min, x_max)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(col_name)\n",
    "    plt.title('1D Scatter Plot of '+col_name+' by Numeric Classes')\n",
    "    plt.show()\n",
    "\n",
    "for col in top_20_columns:  \n",
    "    draw_plot(col,x_min=-1.5, x_max=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.1\n",
    "# create a simple classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test to 1D arrays\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Create and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
